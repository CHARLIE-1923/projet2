{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8aa8b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgdown\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import streamlit as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "# VERIFICATION DU FICHIER TMDB\n",
    "\n",
    "id_drive = '1VB5_gl1fnyBDzcIOXZ5vUSbCY68VZN1v'\n",
    "output_tmdb = 'tmdb_final.csv'\n",
    "url_drive = f'https://drive.google.com/uc?id={id_drive}'\n",
    "\n",
    "if not os.path.exists(output_tmdb):\n",
    "    print(\"téléchargement\")\n",
    "    gdown.download(url_drive, output_tmdb, quiet=False)\n",
    "else:\n",
    "    print(\"Fichier présent\")\n",
    "\n",
    "print(\"Chargement TMDB...\")\n",
    "\n",
    "df_tmdb = pd.read_csv(output_tmdb)\n",
    "\n",
    "# Nettoyage JSON\n",
    "\n",
    "def clean_json(x):\n",
    "    try:\n",
    "        if pd.isna(x): return np.nan\n",
    "        data = json.loads(x.replace(\"'\", '\"'))\n",
    "        return \", \".join([i['name'] for i in data])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "if 'production_companies' in df_tmdb.columns:\n",
    "    df_tmdb['companies_clean'] = df_tmdb['production_companies'].apply(clean_json)\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "\n",
    "cols_drop = ['homepage', 'video', 'backdrop_path', 'status', 'production_companies', 'production_countries']\n",
    "df_tmdb = df_tmdb.drop(columns=[c for c in cols_drop if c in df_tmdb.columns])\n",
    "\n",
    "\n",
    "# IMDb BASICS\n",
    "print(\"IMDb Basics : Sélection (>= 1960)...\")\n",
    "url_basics = \"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "chunks_basics = []\n",
    "\n",
    "if 'imdb_id' in df_tmdb.columns:\n",
    "    ids_tmdb = set(df_tmdb['imdb_id'].dropna())\n",
    "else:\n",
    "    ids_tmdb = set()\n",
    "\n",
    "with pd.read_csv(url_basics, sep='\\t', compression='gzip', \n",
    "                 usecols=['tconst', 'titleType', 'startYear', 'isAdult', 'primaryTitle'], \n",
    "                 chunksize=500000) as reader:\n",
    "    for chunk in reader:\n",
    "        chunk['startYear'] = pd.to_numeric(chunk['startYear'], errors='coerce')\n",
    "        chunk['isAdult'] = pd.to_numeric(chunk['isAdult'], errors='coerce').fillna(0)\n",
    "        mask = ((chunk['titleType'] == 'movie') & (chunk['isAdult'] == 0) & (chunk['startYear'] >= 1960) & (chunk['tconst'].isin(ids_tmdb)))\n",
    "        \n",
    "        res = chunk[mask]\n",
    "        if not res.empty:\n",
    "            chunks_basics.append(res[['tconst', 'primaryTitle', 'startYear']])\n",
    "\n",
    "df_basics = pd.concat(chunks_basics)\n",
    "print(f\"Films retenus (1960-2025) : {len(df_basics)}\")\n",
    "\n",
    "# IMDb DIRECTORS\n",
    "\n",
    "url_principals = \"https://datasets.imdbws.com/title.principals.tsv.gz\"\n",
    "chunks_directors = []\n",
    "ids_films_finaux = set(df_basics['tconst'])\n",
    "\n",
    "with pd.read_csv(url_principals, sep='\\t', compression='gzip', \n",
    "                 usecols=['tconst', 'nconst', 'category'], chunksize=500000) as reader:\n",
    "    for chunk in reader:\n",
    "        mask = (chunk['category'] == 'director') & (chunk['tconst'].isin(ids_films_finaux))\n",
    "        if not chunk[mask].empty:\n",
    "            chunks_directors.append(chunk[mask][['tconst', 'nconst']])\n",
    "\n",
    "if chunks_directors:\n",
    "    df_directors = pd.concat(chunks_directors).drop_duplicates(subset='tconst')\n",
    "    df_basics = pd.merge(df_basics, df_directors, on='tconst', how='left')\n",
    "print(\"IMDb Directors...\")\n",
    "\n",
    "# IMDb AKAS (Régions)\n",
    "\n",
    "url_akas = \"https://datasets.imdbws.com/title.akas.tsv.gz\"\n",
    "chunks_akas = []\n",
    "print(\"IMDb Akas (Régions)...\")\n",
    "with pd.read_csv(url_akas, sep='\\t', compression='gzip', \n",
    "                 usecols=['titleId', 'region', 'language'], chunksize=500000) as reader:\n",
    "    for chunk in reader:\n",
    "        mask = chunk['titleId'].isin(ids_films_finaux)\n",
    "        if not chunk[mask].empty:\n",
    "            chunks_akas.append(chunk[mask].dropna(subset=['region']))\n",
    "\n",
    "if chunks_akas:\n",
    "    df_akas = pd.concat(chunks_akas).drop_duplicates(subset='titleId')\n",
    "    df_basics = pd.merge(df_basics, df_akas, left_on='tconst', right_on='titleId', how='left')\n",
    "\n",
    "\n",
    "# FUSION FINALE\n",
    "\n",
    "print(\"FUSION FINALE...\")\n",
    "df_final = pd.merge(df_basics, df_tmdb, left_on='tconst', right_on='imdb_id', how='inner')\n",
    "df_final = df_final.drop(columns=['titleId', 'imdb_id'])\n",
    "\n",
    "print(f\"résultat final : {len(df_final)} films (1960+).\")\n",
    "display(df_final.head())\n",
    "\n",
    "# EXPORT\n",
    "df_final.to_csv(\"Dataset_1960_Plus.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
